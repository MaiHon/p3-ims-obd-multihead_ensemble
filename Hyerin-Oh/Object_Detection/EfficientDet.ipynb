{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36636e86-9708-4daa-8340-c92c6474d20d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations==0.5.2 in /opt/conda/lib/python3.7/site-packages (0.5.2)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from albumentations==0.5.2) (5.3.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from albumentations==0.5.2) (1.6.3)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from albumentations==0.5.2) (4.5.2.52)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /opt/conda/lib/python3.7/site-packages (from albumentations==0.5.2) (0.18.1)\n",
      "Requirement already satisfied: imgaug>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from albumentations==0.5.2) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from albumentations==0.5.2) (1.18.5)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (2021.4.8)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (2.5.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (3.4.2)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (7.2.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (1.1.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (2.9.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations==0.5.2) (1.14.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations==0.5.2) (4.5.2.52)\n",
      "Requirement already satisfied: Shapely in /opt/conda/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations==0.5.2) (1.7.1)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations==0.5.2) (4.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==0.5.2) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==0.5.2) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==0.5.2) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==0.5.2) (2.8.1)\n",
      "Requirement already satisfied: efficientnet_pytorch in /opt/conda/lib/python3.7/site-packages (0.7.1)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet_pytorch) (1.6.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet_pytorch) (0.18.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet_pytorch) (1.18.5)\n",
      "Requirement already satisfied: pycocotools in /opt/conda/lib/python3.7/site-packages/pycocotools-2.0.2-py3.7-linux-x86_64.egg (2.0.2)\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (46.4.0.post20200518)\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (0.29.23)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (3.4.2)\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (1.18.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (7.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools) (1.14.0)\n",
      "Requirement already satisfied: cython in /opt/conda/lib/python3.7/site-packages (0.29.23)\n",
      "Requirement already satisfied: timm in /opt/conda/lib/python3.7/site-packages/timm-0.4.5-py3.7.egg (0.4.5)\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm) (1.6.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.7.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (0.18.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (1.18.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (7.2.0)\n",
      "Collecting effdet\n",
      "  Downloading effdet-0.2.4-py3-none-any.whl (111 kB)\n",
      "\u001b[K     |████████████████████████████████| 111 kB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting omegaconf>=2.0\n",
      "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: timm>=0.3.2 in /opt/conda/lib/python3.7/site-packages/timm-0.4.5-py3.7.egg (from effdet) (0.4.5)\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from effdet) (1.6.0)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in /opt/conda/lib/python3.7/site-packages/pycocotools-2.0.2-py3.7-linux-x86_64.egg (from effdet) (2.0.2)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from effdet) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from omegaconf>=2.0->effdet) (3.10.0.0)\n",
      "Requirement already satisfied: PyYAML>=5.1.* in /opt/conda/lib/python3.7/site-packages (from omegaconf>=2.0->effdet) (5.3.1)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->effdet) (0.18.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->effdet) (1.18.5)\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools>=2.0.2->effdet) (46.4.0.post20200518)\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.7/site-packages (from pycocotools>=2.0.2->effdet) (0.29.23)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools>=2.0.2->effdet) (3.4.2)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->effdet) (7.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools>=2.0.2->effdet) (1.14.0)\n",
      "Installing collected packages: omegaconf, effdet\n",
      "Successfully installed effdet-0.2.4 omegaconf-2.0.6\n",
      "Collecting gluoncv\n",
      "  Downloading gluoncv-0.10.1.post0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from gluoncv) (1.2.4)\n",
      "Collecting decord\n",
      "  Downloading decord-0.5.2-py3-none-manylinux2010_x86_64.whl (14.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.1 MB 15.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting autocfg\n",
      "  Downloading autocfg-0.0.8-py3-none-any.whl (13 kB)\n",
      "Collecting tensorboardx\n",
      "  Downloading tensorboardX-2.2-py2.py3-none-any.whl (120 kB)\n",
      "\u001b[K     |████████████████████████████████| 120 kB 42.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from gluoncv) (1.18.5)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gluoncv) (4.46.0)\n",
      "Collecting autogluon.core\n",
      "  Downloading autogluon.core-0.2.0-py3-none-any.whl (334 kB)\n",
      "\u001b[K     |████████████████████████████████| 334 kB 41.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from gluoncv) (1.6.3)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from gluoncv) (7.2.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from gluoncv) (4.5.2.52)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from gluoncv) (5.3.1)\n",
      "Collecting yacs\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from gluoncv) (2.23.0)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from gluoncv) (3.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->gluoncv) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->gluoncv) (2020.1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorboardx->gluoncv) (3.16.0)\n",
      "Requirement already satisfied: scikit-learn<0.25,>=0.23.2 in /opt/conda/lib/python3.7/site-packages (from autogluon.core->gluoncv) (0.24.2)\n",
      "Requirement already satisfied: paramiko>=2.4 in /opt/conda/lib/python3.7/site-packages (from autogluon.core->gluoncv) (2.7.2)\n",
      "Collecting dill==0.3.3\n",
      "  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 14.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting autograd>=1.3\n",
      "  Downloading autograd-1.3.tar.gz (38 kB)\n",
      "Collecting dask>=2.6.0\n",
      "  Downloading dask-2021.5.0-py3-none-any.whl (960 kB)\n",
      "\u001b[K     |████████████████████████████████| 960 kB 41.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n",
      "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting distributed>=2.6.0\n",
      "  Downloading distributed-2021.5.0-py3-none-any.whl (699 kB)\n",
      "\u001b[K     |████████████████████████████████| 699 kB 59.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tornado>=5.0.1 in /opt/conda/lib/python3.7/site-packages (from autogluon.core->gluoncv) (6.1)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (from autogluon.core->gluoncv) (1.17.69)\n",
      "Requirement already satisfied: cython in /opt/conda/lib/python3.7/site-packages (from autogluon.core->gluoncv) (0.29.23)\n",
      "Collecting ConfigSpace==0.4.18\n",
      "  Downloading ConfigSpace-0.4.18.tar.gz (950 kB)\n",
      "\u001b[K     |████████████████████████████████| 950 kB 54.5 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->gluoncv) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->gluoncv) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->gluoncv) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->gluoncv) (1.25.8)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->gluoncv) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->gluoncv) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->gluoncv) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->gluoncv) (1.14.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn<0.25,>=0.23.2->autogluon.core->gluoncv) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn<0.25,>=0.23.2->autogluon.core->gluoncv) (2.1.0)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from paramiko>=2.4->autogluon.core->gluoncv) (1.4.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /opt/conda/lib/python3.7/site-packages (from paramiko>=2.4->autogluon.core->gluoncv) (2.9.2)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in /opt/conda/lib/python3.7/site-packages (from paramiko>=2.4->autogluon.core->gluoncv) (3.2.0)\n",
      "Requirement already satisfied: future>=0.15.2 in /opt/conda/lib/python3.7/site-packages (from autograd>=1.3->autogluon.core->gluoncv) (0.18.2)\n",
      "Collecting cloudpickle>=1.1.1\n",
      "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Collecting fsspec>=0.6.0\n",
      "  Downloading fsspec-2021.5.0-py3-none-any.whl (111 kB)\n",
      "\u001b[K     |████████████████████████████████| 111 kB 55.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting partd>=0.3.10\n",
      "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
      "Collecting toolz>=0.8.2\n",
      "  Downloading toolz-0.11.1-py3-none-any.whl (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 5.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting sortedcontainers!=2.0.0,!=2.0.1\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting msgpack>=0.6.0\n",
      "  Downloading msgpack-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (273 kB)\n",
      "\u001b[K     |████████████████████████████████| 273 kB 54.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click>=6.6 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.6.0->autogluon.core->gluoncv) (7.1.2)\n",
      "Requirement already satisfied: psutil>=5.0 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.6.0->autogluon.core->gluoncv) (5.7.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from distributed>=2.6.0->autogluon.core->gluoncv) (46.4.0.post20200518)\n",
      "Collecting zict>=0.1.3\n",
      "  Downloading zict-2.0.0-py3-none-any.whl (10 kB)\n",
      "Collecting tblib>=1.6.0\n",
      "  Downloading tblib-1.7.0-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3->autogluon.core->gluoncv) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.69 in /opt/conda/lib/python3.7/site-packages (from boto3->autogluon.core->gluoncv) (1.20.69)\n",
      "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from boto3->autogluon.core->gluoncv) (0.4.2)\n",
      "Requirement already satisfied: cffi>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from pynacl>=1.0.1->paramiko>=2.4->autogluon.core->gluoncv) (1.14.0)\n",
      "Collecting locket\n",
      "  Downloading locket-0.2.1-py2.py3-none-any.whl (4.1 kB)\n",
      "Collecting heapdict\n",
      "  Downloading HeapDict-1.0.1-py3-none-any.whl (3.9 kB)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.4.1->pynacl>=1.0.1->paramiko>=2.4->autogluon.core->gluoncv) (2.20)\n",
      "Building wheels for collected packages: autograd, ConfigSpace\n",
      "  Building wheel for autograd (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for autograd: filename=autograd-1.3-py3-none-any.whl size=47990 sha256=efe9db05861497fd0d75c44709a269fdbf348e4bd20cfd51b31d0725a0cc345b\n",
      "  Stored in directory: /opt/ml/.cache/pip/wheels/ef/32/31/0e87227cd0ca1d99ad51fbe4b54c6fa02afccf7e483d045e04\n",
      "  Building wheel for ConfigSpace (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ConfigSpace: filename=ConfigSpace-0.4.18-cp37-cp37m-linux_x86_64.whl size=2905655 sha256=c1af1a4396dcec564bf478a08d15846ce2ef26cdcc90d078508d838246fb1120\n",
      "  Stored in directory: /opt/ml/.cache/pip/wheels/36/f7/0f/36f368c419ea1a8024fc3d6c078c3111dfef43fa1d14cfebe0\n",
      "Successfully built autograd ConfigSpace\n",
      "\u001b[31mERROR: autogluon-core 0.2.0 has requirement numpy==1.19.5, but you'll have numpy 1.18.5 which is incompatible.\u001b[0m\n",
      "Installing collected packages: decord, autocfg, tensorboardx, dill, autograd, cloudpickle, fsspec, locket, toolz, partd, dask, graphviz, sortedcontainers, msgpack, heapdict, zict, tblib, distributed, ConfigSpace, autogluon.core, yacs, portalocker, gluoncv\n",
      "Successfully installed ConfigSpace-0.4.18 autocfg-0.0.8 autogluon.core-0.2.0 autograd-1.3 cloudpickle-1.6.0 dask-2021.5.0 decord-0.5.2 dill-0.3.3 distributed-2021.5.0 fsspec-2021.5.0 gluoncv-0.10.1.post0 graphviz-0.8.4 heapdict-1.0.1 locket-0.2.1 msgpack-1.0.2 partd-1.2.0 portalocker-2.3.0 sortedcontainers-2.4.0 tblib-1.7.0 tensorboardx-2.2 toolz-0.11.1 yacs-0.1.8 zict-2.0.0\n",
      "Collecting mxnet\n",
      "  Downloading mxnet-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (46.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 46.9 MB 6.9 MB/s eta 0:00:01    |▉                               | 1.2 MB 1.9 MB/s eta 0:00:25     |█▏                              | 1.8 MB 1.9 MB/s eta 0:00:24     |█▍                              | 2.0 MB 1.9 MB/s eta 0:00:24     |████▏                           | 6.2 MB 5.7 MB/s eta 0:00:08     |█████▌                          | 8.0 MB 5.7 MB/s eta 0:00:07     |██████                          | 8.9 MB 5.7 MB/s eta 0:00:07     |██████████▉                     | 15.9 MB 6.5 MB/s eta 0:00:05     |████████████████                | 23.5 MB 6.7 MB/s eta 0:00:04     |████████████████████▌           | 30.1 MB 6.4 MB/s eta 0:00:03     |███████████████████████████▊    | 40.6 MB 8.0 MB/s eta 0:00:01     |████████████████████████████    | 41.0 MB 8.0 MB/s eta 0:00:01     |█████████████████████████████▏  | 42.8 MB 6.9 MB/s eta 0:00:01     |██████████████████████████████▊ | 45.0 MB 6.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: graphviz<0.9.0,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from mxnet) (0.8.4)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /opt/conda/lib/python3.7/site-packages (from mxnet) (2.23.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /opt/conda/lib/python3.7/site-packages (from mxnet) (1.18.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
      "Installing collected packages: mxnet\n",
      "Successfully installed mxnet-1.8.0.post0\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations==0.5.2\n",
    "!pip install efficientnet_pytorch\n",
    "!pip install pycocotools\n",
    "!pip install cython\n",
    "!pip install timm\n",
    "!pip install effdet\n",
    "!pip install gluoncv\n",
    "!pip install mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaae8a30-4bcf-4042-8f95-b8fb6e410936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import gluoncv.utils as gcv\n",
    "import torch\n",
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain\n",
    "from effdet.efficientdet import HeadNet\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import math\n",
    "warnings.filterwarnings(action='ignore') \n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9f488e4-265b-4efe-aea4-a20e950a1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce467532-7c1e-4e81-82ae-537586bae48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 200\n",
    "seed = 41\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cdd5cda-345f-4144-8c41-c0b057658c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_DEFAULT_MEAN = [x * 255 for x in (0.485, 0.456, 0.406)]\n",
    "IMAGENET_DEFAULT_STD = [x * 255 for x in (0.229, 0.224, 0.225)]\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    '''\n",
    "      data_dir: data가 존재하는 폴더 경로\n",
    "      transforms: data transform (resize, crop, Totensor, etc,,,)\n",
    "    '''\n",
    "    def __init__(self, annotation, data_dir, transforms):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        # coco annotation 불러오기 (coco API)\n",
    "        self.coco = COCO(annotation)\n",
    "        self.predictions = {\n",
    "            \"images\": self.coco.dataset[\"images\"].copy(),\n",
    "            \"categories\": self.coco.dataset[\"categories\"].copy(),\n",
    "            \"annotations\": None\n",
    "        }\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "        image, boxes, labels = self.load_image_and_boxes(index)\n",
    "\n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        target['image_id'] = torch.tensor([index])\n",
    "        \n",
    "        # Multi Scale\n",
    "        target['img_size'] = torch.tensor([(512, 512)])\n",
    "        target['img_scale'] = torch.tensor([1.])\n",
    "        \n",
    "        if self.transforms:\n",
    "            # Transform 적용 후 Box가 없다면 있을 때 까지 반복 (default = 10)\n",
    "            for i in range(10):\n",
    "                sample = {\n",
    "                    'image': image,\n",
    "                    'bboxes': target['boxes'],\n",
    "                    'labels': target['labels']\n",
    "                }\n",
    "                sample = self.transforms(**sample)\n",
    "                if len(sample['bboxes']) > 0:\n",
    "                    image = sample['image']\n",
    "                    target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "                    target['boxes'][:,[0,1,2,3]] = target['boxes'][:,[1,0,3,2]]  #yxyx: be warning\n",
    "                    target['labels'] = torch.tensor(sample['labels'])\n",
    "                    break\n",
    "        \n",
    "        return image, target, image_id\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.coco.getImgIds())\n",
    "    \n",
    "    def load_image_and_boxes(self, index):\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "        image_info = self.coco.loadImgs(image_id)[0]\n",
    "        \n",
    "        image = cv2.imread(os.path.join(self.data_dir, image_info['file_name']))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image = (image - IMAGENET_DEFAULT_MEAN) / IMAGENET_DEFAULT_STD\n",
    "\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=image_info['id'])\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "        boxes = np.array([x['bbox'] for x in anns])\n",
    "        \n",
    "        labels = np.array([x['category_id'] for x in anns])\n",
    "        #labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        # boxex (x_min, y_min, x_max, y_max)\n",
    "        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
    "        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
    "        return image, boxes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70bd9247-a4f2-4571-a80a-c70152e4c362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=4.08s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.87s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "def get_train_transform():\n",
    "    return A.Compose([\n",
    "        A.Resize(512, 512),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params=A.BboxParams(\n",
    "            format='pascal_voc',\n",
    "            min_area=0, \n",
    "            min_visibility=0,\n",
    "            label_fields=['labels'])\n",
    "    )\n",
    "\n",
    "def get_valid_transform():\n",
    "    return A.Compose([\n",
    "        A.Resize(512, 512),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params=A.BboxParams(\n",
    "            format='pascal_voc',\n",
    "            min_area=0, \n",
    "            min_visibility=0,\n",
    "            label_fields=['labels'])\n",
    "    )\n",
    "\n",
    "train_annotation = '/opt/ml/input/data/train.json'\n",
    "val_annotation = '/opt/ml/input/data/val.json'\n",
    "data_dir = '/opt/ml/input/data'\n",
    "train_dataset = CustomDataset(train_annotation, data_dir, get_train_transform())\n",
    "val_dataset = CustomDataset(val_annotation, data_dir, get_valid_transform())\n",
    "\n",
    "train_data_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True,collate_fn=collate_fn,num_workers=0)\n",
    "val_data_loader=DataLoader(val_dataset,batch_size=batch_size,shuffle=False,collate_fn=collate_fn,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18b47513-7f04-49f9-b0c7-0a8058e63e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    # get weight\n",
    "    # url : https://github.com/rwightman/efficientdet-pytorch\n",
    "    config = get_efficientdet_config('tf_efficientdet_d4')\n",
    "    config.image_size = (512, 512)\n",
    "    config.norm_kwargs=dict(eps=.001, momentum=.01)\n",
    "    net = EfficientDet(config, pretrained_backbone=True)\n",
    "    checkpoint = torch.load('./pretrained_weight/tf_efficientdet_d4_49-f56376d9.pth')\n",
    "    net.load_state_dict(checkpoint)\n",
    "\n",
    "    net.reset_head(num_classes=11)\n",
    "    net.class_net = HeadNet(config, num_outputs=11)\n",
    "    return DetBenchTrain(net, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65a801cf-09b1-4a78-92e8-8c4b897231c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=100, verbose=False, delta=0, path=None):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_mAP, model):\n",
    "        score = val_mAP\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        model.eval()\n",
    "        torch.save(model.state_dict(), self.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e90771e-5dab-425f-939c-759a1d2ca688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use freeze : model.apply(freeze_backbone)\n",
    "# Use Unfreeze : model.apply(Unfreeze_backbone)\n",
    "def freeze_backbone(m):\n",
    "    classname = m.__class__.__name__\n",
    "    for ntl in ['EfficientNet', 'BiFPN']:\n",
    "        if ntl in classname:\n",
    "            for param in m.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "def Unfreeze_backbone(m):\n",
    "    classname = m.__class__.__name__\n",
    "    for ntl in ['EfficientNet', 'BiFPN']:\n",
    "        if ntl in classname:\n",
    "            for param in m.parameters():\n",
    "                param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10ef9dcd-56bf-48f6-b3e9-a95ea9ea530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, train_data_loader, val_data_loader, optimizer, device):\n",
    "    model.train()\n",
    "    train_loss = AverageMeter()\n",
    "    train_cls_loss = AverageMeter()\n",
    "    train_box_loss = AverageMeter()\n",
    "    save_path = './saved/checkpoint.pth'\n",
    "    early_stop = EarlyStopping(path=save_path)\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss.reset()\n",
    "        train_cls_loss.reset()\n",
    "        train_box_loss.reset()\n",
    "        model.train()\n",
    "        for images, targets, image_ids in tqdm(train_data_loader):\n",
    "            # gpu 계산을 위해 image.to(device)\n",
    "            images = torch.stack(images)\n",
    "            images = images.to(device).float()\n",
    "            current_batch_size = images.shape[0]\n",
    "\n",
    "            targets2 = {}\n",
    "            targets2['bbox'] = [target['boxes'].to(device).float() for target in targets] # variable number of instances, so the entire structure can be forced to tensor\n",
    "            targets2['cls'] = [target['labels'].to(device).float() for target in targets]\n",
    "            targets2['image_id'] = torch.tensor([target['image_id'] for target in targets]).to(device).float()\n",
    "            targets2['img_scale'] = torch.tensor([target['img_scale'] for target in targets]).to(device).float()\n",
    "            targets2['img_size'] = torch.tensor([(512, 512) for target in targets]).to(device).float()\n",
    "\n",
    "            # calculate loss\n",
    "            losses, cls_loss, box_loss = model(images, targets2).values()\n",
    "\n",
    "            train_loss.update(losses.detach().item(), current_batch_size)\n",
    "            train_cls_loss.update(cls_loss.detach().item(), current_batch_size)\n",
    "            train_box_loss.update(box_loss.detach().item(), current_batch_size)\n",
    "\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 10.0)\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Evaluation\n",
    "        val_loss, val_mAP = vali_fn(val_data_loader,model,device)\n",
    "        \n",
    "        print(f\"\\nEpoch #{epoch+1} train loss: [{train_loss.avg}] train cls loss : [{train_cls_loss.avg}] train box loss : [{train_box_loss.avg}] validation mAP : [{val_mAP}] \\n\")\n",
    "        wandb.log({\"Train Loss\":train_loss.avg, \"Validation mAP@50\":val_mAP})\n",
    "        early_stop(val_mAP,model)\n",
    "        if early_stop.early_stop:\n",
    "            print('Stop Training.....')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9969ba30-39be-4027-9215-13c068d63d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vali_fn(val_data_loader, model, device):\n",
    "    model.eval()\n",
    "    vali_loss = AverageMeter()\n",
    "    vali_mAP = AverageMeter()\n",
    "    # Custom\n",
    "    metric = gcv.metrics.VOCMApMetric(iou_thresh=0.5)\n",
    "    with torch.no_grad():\n",
    "        for images, targets, image_ids in tqdm(val_data_loader):\n",
    "            # gpu 계산을 위해 image.to(device)\n",
    "            images = torch.stack(images)\n",
    "            images = images.to(device).float()\n",
    "\n",
    "            current_batch_size = images.shape[0]\n",
    "\n",
    "            targets2 = {}\n",
    "            targets2['bbox'] = [target['boxes'].to(device).float() for target in targets] # variable number of instances, so the entire structure can be forced to tensor\n",
    "            targets2['cls'] = [target['labels'].to(device).float() for target in targets]\n",
    "            targets2['image_id'] = torch.tensor([target['image_id'] for target in targets]).to(device).float()\n",
    "            targets2['img_scale'] = torch.tensor([target['img_scale'] for target in targets]).to(device).float()\n",
    "            targets2['img_size'] = torch.tensor([(512, 512) for target in targets]).to(device).float()\n",
    "\n",
    "            outputs = model(images, targets2)\n",
    "\n",
    "            loss = outputs['loss']\n",
    "            det = outputs['detections']\n",
    "\n",
    "            # Calc Metric\n",
    "            for i in range(0, len(det)):\n",
    "                pred_scores=det[i, :, 4].cpu().unsqueeze_(0).numpy()\n",
    "                condition=(pred_scores > 0.05)[0]\n",
    "                gt_boxes=targets2['bbox'][i].cpu().unsqueeze_(0).numpy()[...,[1,0,3,2]] #move to PASCAL VOC from yxyx format\n",
    "                gt_labels=targets2['cls'][i].cpu().unsqueeze_(0).numpy()\n",
    "\n",
    "                pred_bboxes=det[i, :, 0:4].cpu().unsqueeze_(0).numpy()[:, condition, :]\n",
    "                pred_labels=det[i, :, 5].cpu().unsqueeze_(0).numpy()[:, condition]\n",
    "                pred_scores=pred_scores[:, condition]\n",
    "                metric.update(\n",
    "                  pred_bboxes=pred_bboxes,\n",
    "                  pred_labels=pred_labels,\n",
    "                  pred_scores=pred_scores,\n",
    "                  gt_bboxes=gt_boxes,\n",
    "                  gt_labels=gt_labels)\n",
    "\n",
    "            vali_mAP.update(metric.get()[1], current_batch_size)\n",
    "            vali_loss.update(loss.detach().item(), current_batch_size)\n",
    "    \n",
    "    # validation loss\n",
    "    return vali_loss.avg, vali_mAP.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02fbf882-c288-4dc9-9f99-70b3b4667e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b4_aa-818f208c.pth\" to /opt/ml/.cache/torch/hub/checkpoints/tf_efficientnet_b4_aa-818f208c.pth\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './pretrained_weight/tf_efficientdet_d4_49-f56376d9.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-646944d8d5cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# setting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-d6488bc9dfed>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEfficientDet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_backbone\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./pretrained_weight/tf_efficientdet_d4_49-f56376d9.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './pretrained_weight/tf_efficientdet_d4_49-f56376d9.pth'"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = get_model()\n",
    "model.to(device)\n",
    "model.eval()\n",
    "# setting\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.AdamW(params, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2952a0da-a332-4e48-aea4-58ae9bb3a4ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d4820d185a36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "train_fn(model, train_data_loader, val_data_loader, optimizer, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
